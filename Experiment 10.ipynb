{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83e\udde0 Experiment 10: Mini Project Based on NLP Applications\n\n",
        "## \u2728 Project Title: Resume Matcher \u2013 AI-Powered Resume Analysis Tool\n\n",
        "This mini project showcases how **Natural Language Processing (NLP)** can be applied in a real-world scenario: **matching a resume with a job description**.\n\n",
        "### \ud83d\udd0d Objectives:\n",
        "- Extract text from a resume (PDF format)\n",
        "- Preprocess text data using NLP techniques (tokenization, lemmatization, stopword removal)\n",
        "- Compute **cosine similarity** between resume and job description to find match percentage\n",
        "- Identify top keywords from both texts\n",
        "- Visualize keyword comparison using **Plotly**\n",
        "- Provide suggestions for resume improvement based on missing keywords\n\n",
        "This tool assists job applicants in evaluating how well their resume aligns with a specific job description."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Install dependencies (if required)\n",
        "# !pip install streamlit PyPDF2 plotly nltk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import streamlit as st\n",
        "import PyPDF2\n",
        "import re\n",
        "import io\n",
        "import plotly.graph_objects as go\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from collections import Counter\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \ud83d\udce6 Download Required NLTK Resources"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \ud83d\udcda Why NLTK?\n",
        "**Natural Language Toolkit (NLTK)** is a leading platform for building Python programs to work with human language data. We use it here for:\n",
        "- **Tokenization**: Splitting text into individual words\n",
        "- **Stopword Removal**: Filtering out common words like \"and\", \"the\", etc.\n",
        "- **Lemmatization**: Reducing words to their base/root form (e.g., 'running' \u2192 'run')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def download_nltk_data():\n",
        "    try:\n",
        "        nltk.data.find('tokenizers/punkt')\n",
        "        nltk.data.find('corpora/stopwords')\n",
        "        nltk.data.find('corpora/wordnet')\n",
        "    except LookupError:\n",
        "        nltk.download('punkt')\n",
        "        nltk.download('stopwords')\n",
        "        nltk.download('wordnet')\n",
        "\n",
        "download_nltk_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "def process_text(text):\n",
        "    # Load standard English stop words\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    # Tokenize text and convert to lowercase\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    # Keep only alphanumeric words and lemmatize them\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token.isalnum()]\n",
        "    # Remove stopwords from token list\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def process_text(text):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token.isalnum()]\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \ud83d\udce5 Extract Text from Resume PDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def extract_text_from_pdf(pdf_file):\n",
        "    try:\n",
        "        with io.BytesIO(pdf_file.read()) as pdf_stream:\n",
        "            pdf_reader = PyPDF2.PdfReader(pdf_stream)\n",
        "            text = \"\"\n",
        "            for page in pdf_reader.pages:\n",
        "                page_text = page.extract_text()\n",
        "                if page_text:\n",
        "                    text += \" \" + page_text\n",
        "            text = re.sub(r'\\s+', ' ', text)\n",
        "            text = re.sub(r'[^\\w\\s@.,-]', '', text)\n",
        "            return text.lower().strip()\n",
        "    except Exception as e:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \ud83d\udd0d Compare Resume with Job Description"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def compare_resume_with_job(resume_text, job_description):\n",
        "    resume_tokens = process_text(resume_text)\n",
        "    job_tokens = process_text(job_description)\n",
        "    resume_freq = Counter(resume_tokens)\n",
        "    job_freq = Counter(job_tokens)\n",
        "    all_terms = set(resume_tokens + job_tokens)\n",
        "    dot_product = sum(resume_freq[term] * job_freq[term] for term in all_terms)\n",
        "    resume_magnitude = math.sqrt(sum(freq * freq for freq in resume_freq.values()))\n",
        "    job_magnitude = math.sqrt(sum(freq * freq for freq in job_freq.values()))\n",
        "    similarity = dot_product / (resume_magnitude * job_magnitude) if resume_magnitude and job_magnitude else 0\n",
        "    return {\n",
        "        'match_percentage': similarity * 100,\n",
        "        'resume_keywords': resume_freq.most_common(10),\n",
        "        'job_keywords': job_freq.most_common(10)\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \ud83d\udcca Create Keyword Visualization Using Plotly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def create_keyword_visualization(results):\n",
        "    all_words = list(set([w for w, _ in results['resume_keywords']] + [w for w, _ in results['job_keywords']]))\n",
        "    resume_dict = dict(results['resume_keywords'])\n",
        "    job_dict = dict(results['job_keywords'])\n",
        "    max_score = max([score for _, score in results['resume_keywords'] + results['job_keywords']] + [1])\n",
        "    resume_scores = [resume_dict.get(word, 0)/max_score * 100 for word in all_words]\n",
        "    job_scores = [job_dict.get(word, 0)/max_score * 100 for word in all_words]\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Bar(x=resume_scores, y=all_words, name='Resume', orientation='h'))\n",
        "    fig.add_trace(go.Bar(x=job_scores, y=all_words, name='Job Description', orientation='h'))\n",
        "    fig.update_layout(title='Keyword Relevance Comparison', xaxis_title='Relevance Score (%)', yaxis_title='Keywords', barmode='group')\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \ud83d\udda5\ufe0f Main Application Logic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def main():\n",
        "    st.title(\"\ud83d\udcc4 Resume Matcher \u2013 NLP Based Analysis\")\n",
        "    job_description = st.text_area(\"Paste Job Description here \ud83d\udc47\", height=200)\n",
        "    uploaded_file = st.file_uploader(\"Upload Resume (PDF only)\", type=[\"pdf\"])\n",
        "    if uploaded_file and job_description:\n",
        "        resume_text = extract_text_from_pdf(uploaded_file)\n",
        "        if resume_text:\n",
        "            results = compare_resume_with_job(resume_text, job_description)\n",
        "            st.metric(\"Match Score (%)\", f\"{results['match_percentage']:.2f}\")\n",
        "            st.subheader(\"\ud83d\udd11 Top Keywords Comparison\")\n",
        "            st.plotly_chart(create_keyword_visualization(results), use_container_width=True)\n",
        "            missing_keywords = set([word for word, _ in results['job_keywords']]) - set([word for word, _ in results['resume_keywords']])\n",
        "            if missing_keywords:\n",
        "                st.warning(\"Consider including these keywords in your resume for better match:\")\n",
        "                st.markdown(\", \".join(missing_keywords))\n",
        "            else:\n",
        "                st.success(\"Your resume aligns well with the job description!\")\n",
        "        else:\n",
        "            st.error(\"Failed to extract text from PDF.\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \u2705 Conclusion\n\n",
        "This mini project integrates several concepts of **Natural Language Processing** and **Data Visualization** to build an interactive, useful application. It demonstrates how text data from resumes and job descriptions can be compared to:\n",
        "- Identify alignment between a candidate's skills and job requirements\n",
        "- Provide actionable feedback for improving resumes\n",
        "- Use vector space modeling (TF & cosine similarity) to assess text similarity\n\n",
        "**Future Enhancements:**\n",
        "- Support for DOCX format in addition to PDFs\n",
        "- Keyword highlighting directly on resume text\n",
        "- Integration with job portals or resume builders\n\n",
        "This project is a practical demonstration of the power of NLP in job matching scenarios."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}